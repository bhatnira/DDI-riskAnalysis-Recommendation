\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{geometry}
\geometry{margin=1in}

\title{\textbf{Algorithm Pseudocode}\\
\large GPU-Accelerated Semantic Severity Recalibration}
\author{}
\date{}

\begin{document}
\maketitle

\section{Main Recalibration Algorithm}

\begin{algorithm}[H]
\caption{Semantic Severity Recalibration (GPU-Accelerated)}
\label{alg:semantic_main}
\begin{algorithmic}[1]
\Require Dataset $\mathcal{D} = \{(\text{desc}^{(i)}, d_1^{(i)}, d_2^{(i)}, \hat{y}^{(i)}, c^{(i)})\}_{i=1}^{N}$
\Require Severity prototypes $\mathcal{P} = \{P_C, P_{Ma}, P_{Mo}, P_{Mi}\}$
\Require Sentence encoder $f_{\theta}$ (all-MiniLM-L6-v2)
\Require Drug class table $\mathcal{R}$
\Require Weights $w_s = 0.45$, $w_c = 0.25$, $w_d = 0.30$
\Require Target distribution $\mathcal{T} = [0.05, 0.25, 0.60, 0.10]$
\Ensure Recalibrated predictions $\{\tilde{y}^{(i)}\}_{i=1}^{N}$

\State \Comment{\textbf{Phase 1: Batch encode all descriptions on GPU}}
\State $\mathbf{E} \gets \Call{GPUBatchEncode}{f_{\theta}, \{\text{desc}^{(i)}\}_{i=1}^{N}}$ \Comment{Shape: $N \times d$}
\State $\mathbf{E} \gets \mathbf{E} / \|\mathbf{E}\|$ \Comment{Normalize embeddings}

\State \Comment{\textbf{Phase 2: Compute prototype centroids}}
\For{$k \in \{C, Ma, Mo, Mi\}$}
    \State $\mathbf{c}_k \gets \text{mean}(f_{\theta}(P_k))$ \Comment{Class centroid}
    \State $\mathbf{c}_k \gets \mathbf{c}_k / \|\mathbf{c}_k\|$
\EndFor
\State $\mathbf{C} \gets [\mathbf{c}_C; \mathbf{c}_{Ma}; \mathbf{c}_{Mo}; \mathbf{c}_{Mi}]$ \Comment{Centroid matrix: $4 \times d$}

\State \Comment{\textbf{Phase 3: Vectorized similarity computation}}
\State $\mathbf{S}_{sem} \gets \mathbf{E} \cdot \mathbf{C}^T$ \Comment{Cosine similarity: $N \times 4$}
\State $\mathbf{s}_{sem} \gets \Call{ThresholdToScores}{\mathbf{S}_{sem}}$ \Comment{Map to numeric}

\State \Comment{\textbf{Phase 4: Parallel drug class scoring}}
\State $\mathbf{s}_{drug} \gets \Call{ParallelDrugClassRisk}{\{(d_1^{(i)}, d_2^{(i)})\}, \mathcal{R}}$

\State \Comment{\textbf{Phase 5: Confidence adjustment}}
\State $\mathbf{s}_{conf} \gets \Call{AdjustConfidence}{\{\hat{y}^{(i)}\}, \{c^{(i)}\}}$

\State \Comment{\textbf{Phase 6: Weighted combination}}
\State $\mathbf{s}_{final} \gets w_s \cdot \mathbf{s}_{sem} + w_c \cdot \mathbf{s}_{conf} + w_d \cdot \mathbf{s}_{drug}$

\State \Comment{\textbf{Phase 7: Quantile-based target calibration}}
\State $\{\tilde{y}^{(i)}\} \gets \Call{QuantileCalibrate}{\mathbf{s}_{final}, \mathcal{T}}$

\State \Return $\{\tilde{y}^{(i)}\}_{i=1}^{N}$
\end{algorithmic}
\end{algorithm}

\newpage
\section{Semantic Similarity Scoring}

\begin{algorithm}[H]
\caption{ThresholdToScores: Convert Similarities to Severity Scores}
\label{alg:threshold}
\begin{algorithmic}[1]
\Require Similarity matrix $\mathbf{S} \in \mathbb{R}^{N \times 4}$ (columns: Contra, Major, Mod, Minor)
\Require Thresholds $\tau_C = 0.65$, $\tau_{Ma} = 0.55$, $\tau_{Mo} = 0.45$
\Ensure Severity scores $\mathbf{s} \in [1.5, 4.0]^N$

\State $\mathbf{s} \gets \mathbf{1.5}$ \Comment{Initialize all to Minor score}

\For{$i \in \{1, \ldots, N\}$} \Comment{Vectorized in practice}
    \If{$S_{i,0} \geq \tau_C$}
        \State $s_i \gets 4.0$ \Comment{Contraindicated}
    \ElsIf{$S_{i,1} \geq \tau_{Ma}$}
        \State $s_i \gets 3.2$ \Comment{Major}
    \ElsIf{$S_{i,2} \geq \tau_{Mo}$}
        \State $s_i \gets 2.0$ \Comment{Moderate}
    \EndIf
\EndFor

\State \Return $\mathbf{s}$
\end{algorithmic}
\end{algorithm}

\section{Quantile-Based Target Calibration}

\begin{algorithm}[H]
\caption{QuantileCalibrate: Exact Target Distribution Matching}
\label{alg:quantile}
\begin{algorithmic}[1]
\Require Final scores $\mathbf{s}_{final} \in \mathbb{R}^N$
\Require Target distribution $\mathcal{T} = [t_C, t_{Ma}, t_{Mo}, t_{Mi}]$
\Ensure Severity labels $\{\tilde{y}^{(i)}\}_{i=1}^{N}$

\State $\pi \gets \Call{ArgSort}{\mathbf{s}_{final}, \text{descending}}$ \Comment{Sort indices by score}
\State $N \gets |\mathbf{s}_{final}|$

\State \Comment{Compute category boundaries from targets}
\State $n_C \gets \lfloor N \cdot t_C \rfloor$ \Comment{Top 5\%}
\State $n_{Ma} \gets \lfloor N \cdot t_{Ma} \rfloor$ \Comment{Next 25\%}
\State $n_{Mi} \gets \lfloor N \cdot t_{Mi} \rfloor$ \Comment{Bottom 10\%}
\State $n_{Mo} \gets N - n_C - n_{Ma} - n_{Mi}$ \Comment{Remaining 60\%}

\State \Comment{Assign severities by rank}
\State $\tilde{\mathbf{y}} \gets \mathbf{0}^N$
\State $\tilde{y}_{\pi[1:n_C]} \gets \text{``Contraindicated''}$
\State $\tilde{y}_{\pi[n_C+1:n_C+n_{Ma}]} \gets \text{``Major''}$
\State $\tilde{y}_{\pi[n_C+n_{Ma}+1:N-n_{Mi}]} \gets \text{``Moderate''}$
\State $\tilde{y}_{\pi[N-n_{Mi}+1:N]} \gets \text{``Minor''}$

\State \Return $\tilde{\mathbf{y}}$
\end{algorithmic}
\end{algorithm}

\newpage
\section{Confidence Adjustment}

\begin{algorithm}[H]
\caption{AdjustConfidence: Penalize Low-Confidence High-Severity}
\label{alg:confidence}
\begin{algorithmic}[1]
\Require Original predictions $\{\hat{y}^{(i)}\}$ and confidences $\{c^{(i)}\}$
\Require Thresholds $\tau_C = 0.65$, $\tau_{Ma} = 0.50$
\Ensure Confidence-adjusted scores $\mathbf{s}_{conf}$

\State $\phi \gets \{C: 4, Ma: 3, Mo: 2, Mi: 1\}$ \Comment{Label to score map}

\For{$i \in \{1, \ldots, N\}$}
    \State $s_i \gets \phi(\hat{y}^{(i)})$ \Comment{Base score from prediction}
    
    \If{$\hat{y}^{(i)} = \text{``Contraindicated''}$ \textbf{and} $c^{(i)} < \tau_C$}
        \State $s_i \gets 3.0$ \Comment{Downgrade uncertain contraindicated}
    \ElsIf{$\hat{y}^{(i)} \in \{\text{``Contra''}, \text{``Major''}\}$ \textbf{and} $c^{(i)} < \tau_{Ma}$}
        \State $s_i \gets 2.5$ \Comment{Partial downgrade}
    \EndIf
\EndFor

\State \Return $\mathbf{s}_{conf}$
\end{algorithmic}
\end{algorithm}

\section{Drug Class Risk Assessment}

\begin{algorithm}[H]
\caption{ParallelDrugClassRisk: Pharmacological Risk Scoring}
\label{alg:drug_class}
\begin{algorithmic}[1]
\Require Drug pairs $\{(d_1^{(i)}, d_2^{(i)})\}_{i=1}^{N}$
\Require High-risk classes $\mathcal{R} = \{\text{anticoag}, \text{antiplate}, \text{QT}, \text{MAOI}, \ldots\}$
\Ensure Drug class scores $\mathbf{s}_{drug}$

\State \Comment{Parallel execution on 24 CPU cores}
\State \textbf{parallel for} $i \in \{1, \ldots, N\}$ \textbf{do}
    \State $C_1 \gets \Call{GetClasses}{d_1^{(i)}, \mathcal{R}}$
    \State $C_2 \gets \Call{GetClasses}{d_2^{(i)}, \mathcal{R}}$
    \State $O \gets C_1 \cap C_2$ \Comment{Overlap}
    
    \If{$\text{``MAOI''} \in C_1 \land \text{``Serotonergic''} \in C_2$}
        \State $s_i \gets 4.0$ \Comment{Fatal combination}
    \ElsIf{$\text{``MAOI''} \in O$}
        \State $s_i \gets 4.0$
    \ElsIf{$\text{``anticoag''} \in O \lor \text{``QT''} \in O$}
        \State $s_i \gets 3.5$
    \ElsIf{$C_1 \neq \emptyset \land C_2 \neq \emptyset$}
        \State $s_i \gets 3.0$
    \ElsIf{$C_1 \neq \emptyset \lor C_2 \neq \emptyset$}
        \State $s_i \gets 2.5$
    \Else
        \State $s_i \gets 2.0$
    \EndIf
\State \textbf{end parallel for}

\State \Return $\mathbf{s}_{drug}$
\end{algorithmic}
\end{algorithm}

\newpage
\section{Complexity Analysis}

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Phase} & \textbf{Time Complexity} & \textbf{Actual Time} \\
\hline
GPU Batch Encoding & $O(N \cdot d / B)$ & 45.5s \\
Centroid Computation & $O(|\mathcal{P}| \cdot d)$ & $<$1s \\
Similarity Matrix & $O(N \cdot 4)$ & 0.04s \\
Drug Class Scoring & $O(N / P)$ & 0.7s \\
Confidence Adjustment & $O(N)$ & $<$1s \\
Quantile Calibration & $O(N \log N)$ & $<$1s \\
\hline
\textbf{Total} & $O(N \cdot d / B + N \log N)$ & \textbf{49.2s} \\
\hline
\end{tabular}
\caption{Complexity analysis for $N = 759,774$, $d = 384$, $B = 8192$, $P = 24$ cores}
\end{table}

\section{Performance Summary}

\begin{itemize}
    \item \textbf{GPU}: NVIDIA RTX PRO 5000 (48GB VRAM)
    \item \textbf{CPU}: 24 cores for parallel drug class scoring
    \item \textbf{Memory}: 124GB RAM
    \item \textbf{Throughput}: 15,454 interactions/second
    \item \textbf{Embedding Rate}: 16,696 descriptions/second
    \item \textbf{Total Time}: 49.2 seconds for 759,774 interactions
    \item \textbf{Target Match}: Exact (0\% deviation from literature targets)
\end{itemize}

\end{document}
