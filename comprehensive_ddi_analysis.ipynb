{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ff965f",
   "metadata": {},
   "source": [
    "# Comprehensive Drug-Drug Interaction (DDI) Analysis\n",
    "## AI-based Polypharmacy Risk-aware Drug Recommender System\n",
    "\n",
    "This notebook provides a comprehensive analysis of the cardiovascular and antithrombotic drug-drug interaction dataset, aligned with the methodology of AI-based polypharmacy risk assessment.\n",
    "\n",
    "### Table of Contents\n",
    "1. Data Loading & Overview\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Drug Classification Analysis\n",
    "4. Severity Distribution Analysis\n",
    "5. Network Analysis of Drug Interactions\n",
    "6. AI/ML-based Risk Prediction Model\n",
    "7. Polypharmacy Risk Assessment\n",
    "8. Summary Tables & Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd85b112",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('ddi_cardio_or_antithrombotic_labeled (1).csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal Drug-Drug Interactions: {len(df):,}\")\n",
    "print(f\"Number of Features: {len(df.columns)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NUMERICAL STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60554672",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Table 1: Dataset Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique drugs analysis\n",
    "unique_drugs_1 = df['drug_name_1'].nunique()\n",
    "unique_drugs_2 = df['drug_name_2'].nunique()\n",
    "all_drugs = set(df['drug_name_1'].unique()) | set(df['drug_name_2'].unique())\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TABLE 1: DATASET SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_stats = {\n",
    "    'Metric': [\n",
    "        'Total DDI Records',\n",
    "        'Unique Drugs (Drug 1 position)',\n",
    "        'Unique Drugs (Drug 2 position)',\n",
    "        'Total Unique Drugs',\n",
    "        'Unique DrugBank IDs',\n",
    "        'Severity Categories',\n",
    "        'Cardiovascular Drugs',\n",
    "        'Antithrombotic Drugs'\n",
    "    ],\n",
    "    'Count': [\n",
    "        len(df),\n",
    "        unique_drugs_1,\n",
    "        unique_drugs_2,\n",
    "        len(all_drugs),\n",
    "        len(set(df['drugbank_id_1'].unique()) | set(df['drugbank_id_2'].unique())),\n",
    "        df['severity_label'].nunique(),\n",
    "        df[df['is_cardiovascular_1'] | df['is_cardiovascular_2']].shape[0],\n",
    "        df[df['is_antithrombotic_1'] | df['is_antithrombotic_2']].shape[0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_table = pd.DataFrame(summary_stats)\n",
    "summary_table['Count'] = summary_table['Count'].apply(lambda x: f\"{x:,}\")\n",
    "print(summary_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a723fc",
   "metadata": {},
   "source": [
    "### Figure 1: Severity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Severity Distribution Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Pie chart for severity labels\n",
    "severity_counts = df['severity_label'].value_counts()\n",
    "colors = ['#ff6b6b', '#feca57', '#48dbfb', '#1dd1a1', '#5f27cd']\n",
    "explode = [0.05] * len(severity_counts)\n",
    "\n",
    "axes[0].pie(severity_counts.values, labels=severity_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors[:len(severity_counts)], explode=explode[:len(severity_counts)],\n",
    "            shadow=True, startangle=90)\n",
    "axes[0].set_title('Figure 1a: Distribution of DDI Severity Labels', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart for severity\n",
    "bars = axes[1].bar(severity_counts.index, severity_counts.values, color=colors[:len(severity_counts)], edgecolor='black')\n",
    "axes[1].set_xlabel('Severity Label', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Interactions', fontsize=12)\n",
    "axes[1].set_title('Figure 1b: Count of DDIs by Severity Level', fontsize=14, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, severity_counts.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000,\n",
    "                 f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1_severity_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSeverity Distribution Table:\")\n",
    "severity_df = pd.DataFrame({\n",
    "    'Severity Label': severity_counts.index,\n",
    "    'Count': severity_counts.values,\n",
    "    'Percentage': (severity_counts.values / len(df) * 100).round(2)\n",
    "})\n",
    "print(severity_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0078f12",
   "metadata": {},
   "source": [
    "### Figure 2: Severity Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7146098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Score Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Overall confidence distribution\n",
    "axes[0, 0].hist(df['severity_confidence'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(df['severity_confidence'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"severity_confidence\"].mean():.3f}')\n",
    "axes[0, 0].axvline(df['severity_confidence'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"severity_confidence\"].median():.3f}')\n",
    "axes[0, 0].set_xlabel('Confidence Score', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0, 0].set_title('Figure 2a: Overall Severity Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Box plot by severity label\n",
    "df.boxplot(column='severity_confidence', by='severity_label', ax=axes[0, 1])\n",
    "axes[0, 1].set_xlabel('Severity Label', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Confidence Score', fontsize=12)\n",
    "axes[0, 1].set_title('Figure 2b: Confidence by Severity Level', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(data=df, x='severity_label', y='severity_confidence', ax=axes[1, 0], palette='Set2')\n",
    "axes[1, 0].set_xlabel('Severity Label', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Confidence Score', fontsize=12)\n",
    "axes[1, 0].set_title('Figure 2c: Confidence Distribution (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# KDE plot by severity\n",
    "for label in df['severity_label'].unique():\n",
    "    subset = df[df['severity_label'] == label]['severity_confidence']\n",
    "    sns.kdeplot(subset, ax=axes[1, 1], label=label, linewidth=2)\n",
    "axes[1, 1].set_xlabel('Confidence Score', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Density', fontsize=12)\n",
    "axes[1, 1].set_title('Figure 2d: Confidence KDE by Severity', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2_confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e1dc7",
   "metadata": {},
   "source": [
    "## 3. Drug Classification Analysis\n",
    "\n",
    "### Table 2: Drug Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4201bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug Classification Analysis\n",
    "print(\"=\"*60)\n",
    "print(\"TABLE 2: DRUG CATEGORY DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create classification categories\n",
    "df['drug_category'] = df.apply(lambda row: \n",
    "    'Both Cardiovascular' if (row['is_cardiovascular_1'] and row['is_cardiovascular_2']) else\n",
    "    'Both Antithrombotic' if (row['is_antithrombotic_1'] and row['is_antithrombotic_2']) else\n",
    "    'Cardiovascular + Antithrombotic' if ((row['is_cardiovascular_1'] and row['is_antithrombotic_2']) or \n",
    "                                          (row['is_antithrombotic_1'] and row['is_cardiovascular_2'])) else\n",
    "    'Cardiovascular + Other' if (row['is_cardiovascular_1'] or row['is_cardiovascular_2']) else\n",
    "    'Antithrombotic + Other' if (row['is_antithrombotic_1'] or row['is_antithrombotic_2']) else\n",
    "    'Other', axis=1)\n",
    "\n",
    "category_counts = df['drug_category'].value_counts()\n",
    "category_df = pd.DataFrame({\n",
    "    'Drug Category': category_counts.index,\n",
    "    'Count': category_counts.values,\n",
    "    'Percentage': (category_counts.values / len(df) * 100).round(2)\n",
    "})\n",
    "print(category_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d56feb",
   "metadata": {},
   "source": [
    "### Figure 3: Drug Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug Category Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Category distribution\n",
    "colors_cat = plt.cm.Set3(np.linspace(0, 1, len(category_counts)))\n",
    "bars = axes[0].barh(category_counts.index, category_counts.values, color=colors_cat, edgecolor='black')\n",
    "axes[0].set_xlabel('Number of Interactions', fontsize=12)\n",
    "axes[0].set_ylabel('Drug Category', fontsize=12)\n",
    "axes[0].set_title('Figure 3a: DDI Distribution by Drug Category', fontsize=14, fontweight='bold')\n",
    "\n",
    "for bar, count in zip(bars, category_counts.values):\n",
    "    axes[0].text(bar.get_width() + 1000, bar.get_y() + bar.get_height()/2,\n",
    "                 f'{count:,}', va='center', fontsize=10)\n",
    "\n",
    "# Stacked bar chart: Category vs Severity\n",
    "category_severity = pd.crosstab(df['drug_category'], df['severity_label'], normalize='index') * 100\n",
    "category_severity.plot(kind='barh', stacked=True, ax=axes[1], colormap='RdYlGn_r', edgecolor='black')\n",
    "axes[1].set_xlabel('Percentage (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Drug Category', fontsize=12)\n",
    "axes[1].set_title('Figure 3b: Severity Distribution within Drug Categories', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(title='Severity', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure3_drug_category_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5f0f9",
   "metadata": {},
   "source": [
    "### Figure 4: Top Drugs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Drugs by Interaction Count\n",
    "all_drug_interactions = pd.concat([\n",
    "    df[['drug_name_1', 'severity_label']].rename(columns={'drug_name_1': 'drug_name'}),\n",
    "    df[['drug_name_2', 'severity_label']].rename(columns={'drug_name_2': 'drug_name'})\n",
    "])\n",
    "\n",
    "drug_counts = all_drug_interactions['drug_name'].value_counts().head(20)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Top 20 drugs\n",
    "colors_drugs = plt.cm.viridis(np.linspace(0, 1, 20))\n",
    "bars = axes[0].barh(drug_counts.index[::-1], drug_counts.values[::-1], color=colors_drugs, edgecolor='black')\n",
    "axes[0].set_xlabel('Number of Interactions', fontsize=12)\n",
    "axes[0].set_ylabel('Drug Name', fontsize=12)\n",
    "axes[0].set_title('Figure 4a: Top 20 Drugs by Interaction Count', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Top drugs with severity breakdown\n",
    "top_10_drugs = drug_counts.head(10).index.tolist()\n",
    "top_drugs_df = all_drug_interactions[all_drug_interactions['drug_name'].isin(top_10_drugs)]\n",
    "top_drugs_severity = pd.crosstab(top_drugs_df['drug_name'], top_drugs_df['severity_label'])\n",
    "top_drugs_severity = top_drugs_severity.loc[top_10_drugs]  # Maintain order\n",
    "\n",
    "top_drugs_severity.plot(kind='barh', stacked=True, ax=axes[1], colormap='RdYlBu_r', edgecolor='black')\n",
    "axes[1].set_xlabel('Number of Interactions', fontsize=12)\n",
    "axes[1].set_ylabel('Drug Name', fontsize=12)\n",
    "axes[1].set_title('Figure 4b: Top 10 Drugs - Severity Breakdown', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(title='Severity', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure4_top_drugs_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTable 3: Top 20 Drugs by Interaction Count\")\n",
    "top_drugs_table = pd.DataFrame({\n",
    "    'Rank': range(1, 21),\n",
    "    'Drug Name': drug_counts.index,\n",
    "    'Interaction Count': drug_counts.values,\n",
    "    'Percentage': (drug_counts.values / (len(df)*2) * 100).round(2)\n",
    "})\n",
    "print(top_drugs_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3064b",
   "metadata": {},
   "source": [
    "## 4. Interaction Description Analysis\n",
    "\n",
    "### Figure 5: Interaction Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze interaction descriptions\n",
    "import re\n",
    "\n",
    "# Extract key interaction types\n",
    "def categorize_interaction(desc):\n",
    "    desc_lower = str(desc).lower()\n",
    "    if 'anticoagulant' in desc_lower:\n",
    "        return 'Anticoagulant Effect'\n",
    "    elif 'bleeding' in desc_lower or 'hemorrhage' in desc_lower:\n",
    "        return 'Bleeding Risk'\n",
    "    elif 'therapeutic efficacy' in desc_lower:\n",
    "        return 'Efficacy Change'\n",
    "    elif 'metabolism' in desc_lower:\n",
    "        return 'Metabolism Effect'\n",
    "    elif 'adverse effect' in desc_lower:\n",
    "        return 'Adverse Effects'\n",
    "    elif 'serum concentration' in desc_lower:\n",
    "        return 'Concentration Change'\n",
    "    elif 'hypotensive' in desc_lower or 'blood pressure' in desc_lower:\n",
    "        return 'Blood Pressure Effect'\n",
    "    elif 'cardiotoxic' in desc_lower or 'arrhythmia' in desc_lower or 'qt' in desc_lower:\n",
    "        return 'Cardiac Effect'\n",
    "    elif 'nephrotoxic' in desc_lower or 'kidney' in desc_lower:\n",
    "        return 'Nephrotoxic Effect'\n",
    "    elif 'hepatotoxic' in desc_lower or 'liver' in desc_lower:\n",
    "        return 'Hepatotoxic Effect'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['interaction_type'] = df['interaction_description'].apply(categorize_interaction)\n",
    "\n",
    "interaction_counts = df['interaction_type'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Pie chart\n",
    "colors_int = plt.cm.tab20(np.linspace(0, 1, len(interaction_counts)))\n",
    "wedges, texts, autotexts = axes[0].pie(interaction_counts.values, labels=interaction_counts.index,\n",
    "                                        autopct='%1.1f%%', colors=colors_int, startangle=90)\n",
    "axes[0].set_title('Figure 5a: Distribution of Interaction Types', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "bars = axes[1].bar(interaction_counts.index, interaction_counts.values, color=colors_int, edgecolor='black')\n",
    "axes[1].set_xlabel('Interaction Type', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Figure 5b: Count of Interaction Types', fontsize=14, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure5_interaction_types.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTable 4: Interaction Type Distribution\")\n",
    "int_type_table = pd.DataFrame({\n",
    "    'Interaction Type': interaction_counts.index,\n",
    "    'Count': interaction_counts.values,\n",
    "    'Percentage': (interaction_counts.values / len(df) * 100).round(2)\n",
    "})\n",
    "print(int_type_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6585e",
   "metadata": {},
   "source": [
    "### Figure 6: Interaction Type vs Severity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Interaction Type vs Severity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Count heatmap\n",
    "heatmap_data = pd.crosstab(df['interaction_type'], df['severity_label'])\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd', ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Figure 6a: Interaction Type vs Severity (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Severity Label', fontsize=12)\n",
    "axes[0].set_ylabel('Interaction Type', fontsize=12)\n",
    "\n",
    "# Percentage heatmap (normalized by row)\n",
    "heatmap_pct = pd.crosstab(df['interaction_type'], df['severity_label'], normalize='index') * 100\n",
    "sns.heatmap(heatmap_pct, annot=True, fmt='.1f', cmap='Blues', ax=axes[1], cbar_kws={'label': 'Percentage (%)'})\n",
    "axes[1].set_title('Figure 6b: Interaction Type vs Severity (% within Type)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Severity Label', fontsize=12)\n",
    "axes[1].set_ylabel('Interaction Type', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure6_heatmap_interaction_severity.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464d2e7",
   "metadata": {},
   "source": [
    "## 5. Network Analysis of Drug Interactions\n",
    "\n",
    "### Figure 7: Drug Interaction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f733bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Analysis\n",
    "try:\n",
    "    import networkx as nx\n",
    "    \n",
    "    # Create network from top interacting drugs (for visualization)\n",
    "    top_n = 30  # Top drugs to include in network\n",
    "    top_drugs_list = drug_counts.head(top_n).index.tolist()\n",
    "    \n",
    "    # Filter interactions involving top drugs\n",
    "    network_df = df[(df['drug_name_1'].isin(top_drugs_list)) & (df['drug_name_2'].isin(top_drugs_list))]\n",
    "    \n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with severity as weight\n",
    "    for _, row in network_df.iterrows():\n",
    "        if G.has_edge(row['drug_name_1'], row['drug_name_2']):\n",
    "            G[row['drug_name_1']][row['drug_name_2']]['weight'] += 1\n",
    "        else:\n",
    "            G.add_edge(row['drug_name_1'], row['drug_name_2'], \n",
    "                      weight=1, severity=row['severity_numeric'])\n",
    "    \n",
    "    # Calculate network metrics\n",
    "    print(\"=\"*60)\n",
    "    print(\"NETWORK ANALYSIS METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Number of Nodes (Drugs): {G.number_of_nodes()}\")\n",
    "    print(f\"Number of Edges (Interactions): {G.number_of_edges()}\")\n",
    "    print(f\"Network Density: {nx.density(G):.4f}\")\n",
    "    if nx.is_connected(G):\n",
    "        print(f\"Average Shortest Path Length: {nx.average_shortest_path_length(G):.4f}\")\n",
    "    print(f\"Average Clustering Coefficient: {nx.average_clustering(G):.4f}\")\n",
    "    \n",
    "    # Degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Network plot\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "    node_sizes = [degree_centrality[node] * 3000 + 200 for node in G.nodes()]\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, ax=axes[0], node_size=node_sizes, \n",
    "                          node_color=list(degree_centrality.values()), \n",
    "                          cmap=plt.cm.Reds, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, ax=axes[0], alpha=0.3, edge_color='gray')\n",
    "    nx.draw_networkx_labels(G, pos, ax=axes[0], font_size=8)\n",
    "    axes[0].set_title('Figure 7a: Drug Interaction Network (Top 30 Drugs)', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Degree distribution\n",
    "    degrees = [G.degree(n) for n in G.nodes()]\n",
    "    axes[1].hist(degrees, bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_xlabel('Degree (Number of Connections)', fontsize=12)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1].set_title('Figure 7b: Degree Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figure7_network_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Top drugs by centrality\n",
    "    print(\"\\nTable 5: Top 10 Drugs by Degree Centrality\")\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'Drug': list(degree_centrality.keys()),\n",
    "        'Degree Centrality': list(degree_centrality.values())\n",
    "    }).sort_values('Degree Centrality', ascending=False).head(10)\n",
    "    centrality_df['Rank'] = range(1, 11)\n",
    "    centrality_df = centrality_df[['Rank', 'Drug', 'Degree Centrality']]\n",
    "    print(centrality_df.to_string(index=False))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"NetworkX not installed. Install with: pip install networkx\")\n",
    "    print(\"Skipping network analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5a719",
   "metadata": {},
   "source": [
    "## 6. AI/ML-based Risk Prediction Model\n",
    "\n",
    "Building a machine learning model to predict DDI severity based on drug features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ML model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AI/ML-BASED DDI SEVERITY PREDICTION MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create feature matrix\n",
    "ml_df = df.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le_drug1 = LabelEncoder()\n",
    "le_drug2 = LabelEncoder()\n",
    "le_interaction = LabelEncoder()\n",
    "le_severity = LabelEncoder()\n",
    "\n",
    "ml_df['drug1_encoded'] = le_drug1.fit_transform(ml_df['drug_name_1'])\n",
    "ml_df['drug2_encoded'] = le_drug2.fit_transform(ml_df['drug_name_2'])\n",
    "ml_df['interaction_type_encoded'] = le_interaction.fit_transform(ml_df['interaction_type'])\n",
    "ml_df['severity_encoded'] = le_severity.fit_transform(ml_df['severity_label'])\n",
    "\n",
    "# Features\n",
    "features = ['drug1_encoded', 'drug2_encoded', 'is_cardiovascular_1', 'is_cardiovascular_2',\n",
    "            'is_antithrombotic_1', 'is_antithrombotic_2', 'interaction_type_encoded']\n",
    "\n",
    "X = ml_df[features].astype(float)\n",
    "y = ml_df['severity_encoded']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train):,}\")\n",
    "print(f\"Test set size: {len(X_test):,}\")\n",
    "print(f\"Number of features: {len(features)}\")\n",
    "print(f\"Number of classes: {len(le_severity.classes_)}\")\n",
    "print(f\"Classes: {list(le_severity.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6109bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABLE 6: MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "results_df = pd.DataFrame(results)\n",
    "for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n",
    "    results_df[col] = results_df[col].apply(lambda x: f\"{x:.4f}\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81686946",
   "metadata": {},
   "source": [
    "### Figure 8: Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Performance comparison bar chart\n",
    "results_numeric = pd.DataFrame(results)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(results_numeric['Model']))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[0, 0].bar(x + i*width, results_numeric[metric], width, label=metric)\n",
    "\n",
    "axes[0, 0].set_xlabel('Model', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Score', fontsize=12)\n",
    "axes[0, 0].set_title('Figure 8a: Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x + width * 1.5)\n",
    "axes[0, 0].set_xticklabels(results_numeric['Model'])\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "\n",
    "# Confusion Matrix for best model (Random Forest)\n",
    "rf_model = models['Random Forest']\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1],\n",
    "            xticklabels=le_severity.classes_, yticklabels=le_severity.classes_)\n",
    "axes[0, 1].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Actual', fontsize=12)\n",
    "axes[0, 1].set_title('Figure 8b: Confusion Matrix (Random Forest)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "axes[1, 0].barh(feature_importance['Feature'], feature_importance['Importance'], \n",
    "                color='steelblue', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Importance', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Feature', fontsize=12)\n",
    "axes[1, 0].set_title('Figure 8c: Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Classification Report Heatmap\n",
    "report = classification_report(y_test, y_pred_rf, target_names=le_severity.classes_, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose().iloc[:-3, :-1]  # Remove avg rows and support column\n",
    "sns.heatmap(report_df, annot=True, fmt='.2f', cmap='RdYlGn', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Figure 8d: Classification Report Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure8_model_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad819ad7",
   "metadata": {},
   "source": [
    "## 7. Polypharmacy Risk Assessment\n",
    "\n",
    "### Table 7: High-Risk Drug Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-risk drug combinations\n",
    "print(\"=\"*60)\n",
    "print(\"POLYPHARMACY RISK ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filter contraindicated interactions\n",
    "contraindicated = df[df['severity_label'] == 'Contraindicated interaction'].copy()\n",
    "print(f\"\\nTotal Contraindicated Interactions: {len(contraindicated):,}\")\n",
    "\n",
    "# High confidence contraindicated\n",
    "high_risk = contraindicated[contraindicated['severity_confidence'] > 0.7]\n",
    "print(f\"High Confidence (>0.7) Contraindicated: {len(high_risk):,}\")\n",
    "\n",
    "# Most dangerous drug pairs\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABLE 7: TOP 20 HIGHEST-RISK DRUG COMBINATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "high_risk_sorted = high_risk.nlargest(20, 'severity_confidence')\n",
    "risk_table = high_risk_sorted[['drug_name_1', 'drug_name_2', 'severity_confidence', \n",
    "                                'interaction_description']].copy()\n",
    "risk_table['severity_confidence'] = risk_table['severity_confidence'].apply(lambda x: f\"{x:.4f}\")\n",
    "risk_table['interaction_description'] = risk_table['interaction_description'].apply(lambda x: x[:80] + '...' if len(str(x)) > 80 else x)\n",
    "risk_table.columns = ['Drug 1', 'Drug 2', 'Confidence', 'Interaction']\n",
    "print(risk_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polypharmacy Risk Score Calculation\n",
    "def calculate_polypharmacy_risk(drug_list, interaction_df):\n",
    "    \"\"\"\n",
    "    Calculate polypharmacy risk score for a given list of drugs.\n",
    "    Higher score indicates higher risk.\n",
    "    \"\"\"\n",
    "    if len(drug_list) < 2:\n",
    "        return 0, []\n",
    "    \n",
    "    risk_score = 0\n",
    "    interactions_found = []\n",
    "    \n",
    "    severity_weights = {\n",
    "        'Contraindicated interaction': 4,\n",
    "        'Major interaction': 3,\n",
    "        'Moderate interaction': 2,\n",
    "        'Minor interaction': 1\n",
    "    }\n",
    "    \n",
    "    for i, drug1 in enumerate(drug_list):\n",
    "        for drug2 in drug_list[i+1:]:\n",
    "            # Find interactions between drug pair\n",
    "            interactions = interaction_df[\n",
    "                ((interaction_df['drug_name_1'] == drug1) & (interaction_df['drug_name_2'] == drug2)) |\n",
    "                ((interaction_df['drug_name_1'] == drug2) & (interaction_df['drug_name_2'] == drug1))\n",
    "            ]\n",
    "            \n",
    "            if len(interactions) > 0:\n",
    "                for _, row in interactions.iterrows():\n",
    "                    weight = severity_weights.get(row['severity_label'], 1)\n",
    "                    score = weight * row['severity_confidence']\n",
    "                    risk_score += score\n",
    "                    interactions_found.append({\n",
    "                        'drug_pair': f\"{drug1} + {drug2}\",\n",
    "                        'severity': row['severity_label'],\n",
    "                        'confidence': row['severity_confidence'],\n",
    "                        'score': score\n",
    "                    })\n",
    "    \n",
    "    return risk_score, interactions_found\n",
    "\n",
    "# Example: Common cardiovascular drug regimen\n",
    "example_drugs = ['Warfarin', 'Aspirin', 'Atorvastatin', 'Lisinopril', 'Metoprolol']\n",
    "risk_score, found_interactions = calculate_polypharmacy_risk(example_drugs, df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE POLYPHARMACY RISK ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDrug Regimen: {', '.join(example_drugs)}\")\n",
    "print(f\"Total Risk Score: {risk_score:.4f}\")\n",
    "print(f\"Number of Interactions Found: {len(found_interactions)}\")\n",
    "\n",
    "if found_interactions:\n",
    "    print(\"\\nInteractions Detected:\")\n",
    "    int_df = pd.DataFrame(found_interactions)\n",
    "    print(int_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f789913",
   "metadata": {},
   "source": [
    "### Figure 9: Risk Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac77e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk Distribution by Drug Category\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Severity by cardiovascular flag\n",
    "cv_severity = pd.crosstab(df['is_cardiovascular_1'] | df['is_cardiovascular_2'], \n",
    "                          df['severity_label'], normalize='index') * 100\n",
    "cv_severity.index = ['Non-Cardiovascular', 'Cardiovascular']\n",
    "cv_severity.plot(kind='bar', ax=axes[0, 0], colormap='RdYlGn_r', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Drug Category', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Percentage (%)', fontsize=12)\n",
    "axes[0, 0].set_title('Figure 9a: Severity by Cardiovascular Involvement', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(title='Severity', bbox_to_anchor=(1.02, 1))\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Severity by antithrombotic flag\n",
    "at_severity = pd.crosstab(df['is_antithrombotic_1'] | df['is_antithrombotic_2'], \n",
    "                          df['severity_label'], normalize='index') * 100\n",
    "at_severity.index = ['Non-Antithrombotic', 'Antithrombotic']\n",
    "at_severity.plot(kind='bar', ax=axes[0, 1], colormap='RdYlGn_r', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Drug Category', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Percentage (%)', fontsize=12)\n",
    "axes[0, 1].set_title('Figure 9b: Severity by Antithrombotic Involvement', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(title='Severity', bbox_to_anchor=(1.02, 1))\n",
    "axes[0, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Confidence distribution by drug category\n",
    "df['involves_cv'] = df['is_cardiovascular_1'] | df['is_cardiovascular_2']\n",
    "df['involves_at'] = df['is_antithrombotic_1'] | df['is_antithrombotic_2']\n",
    "\n",
    "sns.boxplot(data=df, x='involves_cv', y='severity_confidence', ax=axes[1, 0], palette='Set2')\n",
    "axes[1, 0].set_xticklabels(['Non-Cardiovascular', 'Cardiovascular'])\n",
    "axes[1, 0].set_xlabel('Drug Category', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Severity Confidence', fontsize=12)\n",
    "axes[1, 0].set_title('Figure 9c: Confidence by Cardiovascular Involvement', fontsize=14, fontweight='bold')\n",
    "\n",
    "sns.boxplot(data=df, x='involves_at', y='severity_confidence', ax=axes[1, 1], palette='Set2')\n",
    "axes[1, 1].set_xticklabels(['Non-Antithrombotic', 'Antithrombotic'])\n",
    "axes[1, 1].set_xlabel('Drug Category', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Severity Confidence', fontsize=12)\n",
    "axes[1, 1].set_title('Figure 9d: Confidence by Antithrombotic Involvement', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure9_risk_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea8718",
   "metadata": {},
   "source": [
    "## 8. Summary Tables & Key Findings\n",
    "\n",
    "### Table 8: Comprehensive Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32549c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Summary\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dataset Summary\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"DATASET CHARACTERISTICS\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Total Drug-Drug Interactions: {len(df):,}\")\n",
    "print(f\"Unique Drugs: {len(all_drugs):,}\")\n",
    "print(f\"Cardiovascular Drugs Involved: {df[df['is_cardiovascular_1'] | df['is_cardiovascular_2']].shape[0]:,} ({df[df['is_cardiovascular_1'] | df['is_cardiovascular_2']].shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Antithrombotic Drugs Involved: {df[df['is_antithrombotic_1'] | df['is_antithrombotic_2']].shape[0]:,} ({df[df['is_antithrombotic_1'] | df['is_antithrombotic_2']].shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Severity Summary\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"SEVERITY DISTRIBUTION\")\n",
    "print(\"-\"*40)\n",
    "for label, count in severity_counts.items():\n",
    "    print(f\"{label}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Risk Summary\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"RISK ASSESSMENT SUMMARY\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Contraindicated Interactions: {len(contraindicated):,}\")\n",
    "print(f\"High-Confidence Contraindicated (>0.7): {len(high_risk):,}\")\n",
    "print(f\"Average Severity Confidence: {df['severity_confidence'].mean():.4f}\")\n",
    "print(f\"Median Severity Confidence: {df['severity_confidence'].median():.4f}\")\n",
    "\n",
    "# Model Summary\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"ML MODEL PERFORMANCE (Best: Random Forest)\")\n",
    "print(\"-\"*40)\n",
    "best_result = [r for r in results if r['Model'] == 'Random Forest'][0]\n",
    "print(f\"Accuracy: {float(best_result['Accuracy']):.4f}\")\n",
    "print(f\"Precision: {float(best_result['Precision']):.4f}\")\n",
    "print(f\"Recall: {float(best_result['Recall']):.4f}\")\n",
    "print(f\"F1-Score: {float(best_result['F1-Score']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Figure\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Create a summary dashboard\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Severity pie chart\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.pie(severity_counts.values, labels=severity_counts.index, autopct='%1.1f%%',\n",
    "        colors=['#ff6b6b', '#feca57', '#48dbfb', '#1dd1a1'], startangle=90)\n",
    "ax1.set_title('Severity Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Top 10 drugs bar chart\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "top10 = drug_counts.head(10)\n",
    "ax2.barh(top10.index[::-1], top10.values[::-1], color='steelblue', edgecolor='black')\n",
    "ax2.set_xlabel('Interaction Count')\n",
    "ax2.set_title('Top 10 Drugs by Interactions', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Confidence histogram\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax3.hist(df['severity_confidence'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(df['severity_confidence'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"severity_confidence\"].mean():.2f}')\n",
    "ax3.set_xlabel('Confidence Score')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Confidence Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Drug category distribution\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "cat_counts = df['drug_category'].value_counts()\n",
    "ax4.barh(cat_counts.index, cat_counts.values, color=plt.cm.Set3(np.linspace(0, 1, len(cat_counts))), edgecolor='black')\n",
    "ax4.set_xlabel('Count')\n",
    "ax4.set_title('Drug Category Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 5. Interaction type distribution\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "int_counts = df['interaction_type'].value_counts()\n",
    "ax5.pie(int_counts.values, labels=int_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax5.set_title('Interaction Types', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 6. Model comparison\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "model_names = [r['Model'] for r in results]\n",
    "accuracies = [float(r['Accuracy']) for r in results]\n",
    "ax6.bar(model_names, accuracies, color=['#3498db', '#e74c3c', '#2ecc71'], edgecolor='black')\n",
    "ax6.set_ylabel('Accuracy')\n",
    "ax6.set_title('Model Performance', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylim([0, 1])\n",
    "for i, v in enumerate(accuracies):\n",
    "    ax6.text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
    "\n",
    "# 7. Severity by numeric value\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "numeric_counts = df['severity_numeric'].value_counts().sort_index()\n",
    "ax7.bar(numeric_counts.index.astype(str), numeric_counts.values, color=['green', 'yellow', 'orange', 'red'][:len(numeric_counts)], edgecolor='black')\n",
    "ax7.set_xlabel('Severity Numeric')\n",
    "ax7.set_ylabel('Count')\n",
    "ax7.set_title('Severity Numeric Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 8. Feature importance\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "ax8.barh(feature_importance['Feature'], feature_importance['Importance'], color='teal', edgecolor='black')\n",
    "ax8.set_xlabel('Importance')\n",
    "ax8.set_title('Feature Importance (RF)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 9. Key statistics text box\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "ax9.axis('off')\n",
    "stats_text = f\"\"\"\n",
    "KEY STATISTICS\n",
    "{'='*30}\n",
    "\n",
    "Total DDIs: {len(df):,}\n",
    "Unique Drugs: {len(all_drugs):,}\n",
    "\n",
    "Contraindicated: {len(contraindicated):,}\n",
    "High Risk (>0.7): {len(high_risk):,}\n",
    "\n",
    "Avg Confidence: {df['severity_confidence'].mean():.4f}\n",
    "Std Confidence: {df['severity_confidence'].std():.4f}\n",
    "\n",
    "Best Model: Random Forest\n",
    "Accuracy: {float(best_result['Accuracy']):.4f}\n",
    "F1-Score: {float(best_result['F1-Score']):.4f}\n",
    "\"\"\"\n",
    "ax9.text(0.1, 0.5, stats_text, transform=ax9.transAxes, fontsize=11,\n",
    "         verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Drug-Drug Interaction Analysis Dashboard', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.savefig('figure10_summary_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAll figures saved:\")\n",
    "print(\"  - figure1_severity_distribution.png\")\n",
    "print(\"  - figure2_confidence_distribution.png\")\n",
    "print(\"  - figure3_drug_category_analysis.png\")\n",
    "print(\"  - figure4_top_drugs_analysis.png\")\n",
    "print(\"  - figure5_interaction_types.png\")\n",
    "print(\"  - figure6_heatmap_interaction_severity.png\")\n",
    "print(\"  - figure7_network_analysis.png\")\n",
    "print(\"  - figure8_model_performance.png\")\n",
    "print(\"  - figure9_risk_distribution.png\")\n",
    "print(\"  - figure10_summary_dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad76769",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Dataset Scope**: The dataset contains comprehensive drug-drug interaction data with severity classifications and confidence scores.\n",
    "\n",
    "2. **Severity Distribution**: The interactions are classified into multiple severity levels, with contraindicated and major interactions forming a significant portion.\n",
    "\n",
    "3. **Drug Categories**: Cardiovascular and antithrombotic drugs show distinct interaction patterns, with bleeding-related risks being prominent.\n",
    "\n",
    "4. **AI Model Performance**: Machine learning models (especially Random Forest) can effectively predict DDI severity based on drug features.\n",
    "\n",
    "5. **Polypharmacy Risk**: The analysis provides a framework for assessing polypharmacy risk in clinical settings.\n",
    "\n",
    "### Implications for Clinical Practice:\n",
    "\n",
    "- Healthcare providers should be particularly cautious with antithrombotic combinations\n",
    "- AI-based prediction models can assist in early identification of high-risk drug combinations\n",
    "- Polypharmacy risk scoring can help prioritize medication reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea75a29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ—ï¸ AI-based Polypharmacy Risk-aware Drug Recommender System\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "```\n",
    "               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "               â”‚  Drug Input List â”‚\n",
    "               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Interaction Engine â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Severity Predictor â”‚ (ML / GNN)\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Alternative Finder â”‚ (Embedding + Filtering)\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Explanation LLM    â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "This system provides:\n",
    "1. **Drug Input Processing** - Accept and validate drug lists\n",
    "2. **Interaction Detection** - Identify all pairwise DDIs\n",
    "3. **Severity Prediction** - ML-based risk assessment\n",
    "4. **Alternative Recommendations** - Find safer drug substitutes\n",
    "5. **Natural Language Explanations** - Human-readable risk reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5fa14",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Module 1: Drug Input List\n",
    "\n",
    "The entry point that accepts and validates a patient's medication list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e14f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 1: DRUG INPUT LIST\n",
    "# ============================================================================\n",
    "\n",
    "class DrugInputProcessor:\n",
    "    \"\"\"\n",
    "    Processes and validates drug input lists.\n",
    "    Maps drug names to DrugBank IDs and retrieves metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ddi_dataframe):\n",
    "        self.df = ddi_dataframe\n",
    "        # Build drug database from DDI data\n",
    "        self._build_drug_database()\n",
    "    \n",
    "    def _build_drug_database(self):\n",
    "        \"\"\"Build a lookup database of all drugs\"\"\"\n",
    "        drugs_1 = self.df[['drugbank_id_1', 'drug_name_1', 'atc_1', \n",
    "                           'is_cardiovascular_1', 'is_antithrombotic_1']].copy()\n",
    "        drugs_1.columns = ['drugbank_id', 'drug_name', 'atc', 'is_cardiovascular', 'is_antithrombotic']\n",
    "        \n",
    "        drugs_2 = self.df[['drugbank_id_2', 'drug_name_2', 'atc_2',\n",
    "                           'is_cardiovascular_2', 'is_antithrombotic_2']].copy()\n",
    "        drugs_2.columns = ['drugbank_id', 'drug_name', 'atc', 'is_cardiovascular', 'is_antithrombotic']\n",
    "        \n",
    "        self.drug_db = pd.concat([drugs_1, drugs_2]).drop_duplicates(subset=['drugbank_id'])\n",
    "        self.drug_names = set(self.drug_db['drug_name'].str.lower())\n",
    "        self.name_to_id = dict(zip(self.drug_db['drug_name'].str.lower(), self.drug_db['drugbank_id']))\n",
    "        \n",
    "        print(f\"âœ… Drug database built: {len(self.drug_db):,} unique drugs\")\n",
    "    \n",
    "    def validate_drugs(self, drug_list):\n",
    "        \"\"\"\n",
    "        Validate a list of drug names.\n",
    "        Returns validated drugs and any unrecognized entries.\n",
    "        \"\"\"\n",
    "        validated = []\n",
    "        unrecognized = []\n",
    "        \n",
    "        for drug in drug_list:\n",
    "            drug_lower = drug.lower().strip()\n",
    "            if drug_lower in self.drug_names:\n",
    "                validated.append({\n",
    "                    'input_name': drug,\n",
    "                    'drugbank_id': self.name_to_id.get(drug_lower),\n",
    "                    'status': 'valid'\n",
    "                })\n",
    "            else:\n",
    "                # Try fuzzy matching\n",
    "                matches = [d for d in self.drug_names if drug_lower in d or d in drug_lower]\n",
    "                if matches:\n",
    "                    best_match = matches[0]\n",
    "                    validated.append({\n",
    "                        'input_name': drug,\n",
    "                        'matched_name': best_match.title(),\n",
    "                        'drugbank_id': self.name_to_id.get(best_match),\n",
    "                        'status': 'fuzzy_match'\n",
    "                    })\n",
    "                else:\n",
    "                    unrecognized.append(drug)\n",
    "        \n",
    "        return validated, unrecognized\n",
    "    \n",
    "    def get_drug_info(self, drug_name):\n",
    "        \"\"\"Get detailed info for a drug\"\"\"\n",
    "        drug_lower = drug_name.lower()\n",
    "        if drug_lower in self.name_to_id:\n",
    "            drug_id = self.name_to_id[drug_lower]\n",
    "            info = self.drug_db[self.drug_db['drugbank_id'] == drug_id].iloc[0]\n",
    "            return info.to_dict()\n",
    "        return None\n",
    "    \n",
    "    def process_input(self, drug_list):\n",
    "        \"\"\"Main entry point - process a drug list\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"ğŸ“‹ DRUG INPUT PROCESSING\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nInput drugs: {drug_list}\")\n",
    "        \n",
    "        validated, unrecognized = self.validate_drugs(drug_list)\n",
    "        \n",
    "        print(f\"\\nâœ… Validated: {len(validated)} drugs\")\n",
    "        print(f\"âŒ Unrecognized: {len(unrecognized)} drugs\")\n",
    "        \n",
    "        if unrecognized:\n",
    "            print(f\"   Unrecognized: {unrecognized}\")\n",
    "        \n",
    "        return {\n",
    "            'validated_drugs': validated,\n",
    "            'unrecognized': unrecognized,\n",
    "            'drug_count': len(validated)\n",
    "        }\n",
    "\n",
    "# Initialize the Drug Input Processor\n",
    "drug_processor = DrugInputProcessor(df)\n",
    "\n",
    "# Test with example drug list\n",
    "test_drugs = ['Warfarin', 'Aspirin', 'Metoprolol', 'Lisinopril', 'Atorvastatin', 'UnknownDrug123']\n",
    "input_result = drug_processor.process_input(test_drugs)\n",
    "\n",
    "# Show validated drugs\n",
    "print(\"\\nğŸ“Š Validated Drug Details:\")\n",
    "pd.DataFrame(input_result['validated_drugs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875dac8",
   "metadata": {},
   "source": [
    "## âš™ï¸ Module 2: Interaction Engine\n",
    "\n",
    "Detects all pairwise drug-drug interactions from the input list and retrieves interaction details from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58983976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 2: INTERACTION ENGINE\n",
    "# ============================================================================\n",
    "\n",
    "class InteractionEngine:\n",
    "    \"\"\"\n",
    "    Detects drug-drug interactions from a list of drugs.\n",
    "    Queries the DDI database for all pairwise interactions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ddi_dataframe):\n",
    "        self.df = ddi_dataframe\n",
    "        self._build_interaction_index()\n",
    "    \n",
    "    def _build_interaction_index(self):\n",
    "        \"\"\"Build a fast lookup index for interactions\"\"\"\n",
    "        # Create bidirectional lookup\n",
    "        self.interactions = {}\n",
    "        \n",
    "        for _, row in self.df.iterrows():\n",
    "            drug1 = row['drug_name_1'].lower()\n",
    "            drug2 = row['drug_name_2'].lower()\n",
    "            \n",
    "            key1 = (drug1, drug2)\n",
    "            key2 = (drug2, drug1)\n",
    "            \n",
    "            interaction_data = {\n",
    "                'drug_1': row['drug_name_1'],\n",
    "                'drug_2': row['drug_name_2'],\n",
    "                'drugbank_id_1': row['drugbank_id_1'],\n",
    "                'drugbank_id_2': row['drugbank_id_2'],\n",
    "                'description': row['interaction_description'],\n",
    "                'severity_label': row['severity_label'],\n",
    "                'severity_confidence': row['severity_confidence'],\n",
    "                'severity_numeric': row['severity_numeric'],\n",
    "                'is_cardiovascular_1': row['is_cardiovascular_1'],\n",
    "                'is_cardiovascular_2': row['is_cardiovascular_2'],\n",
    "                'is_antithrombotic_1': row['is_antithrombotic_1'],\n",
    "                'is_antithrombotic_2': row['is_antithrombotic_2']\n",
    "            }\n",
    "            \n",
    "            if key1 not in self.interactions:\n",
    "                self.interactions[key1] = []\n",
    "            self.interactions[key1].append(interaction_data)\n",
    "            \n",
    "            if key2 not in self.interactions:\n",
    "                self.interactions[key2] = []\n",
    "            self.interactions[key2].append(interaction_data)\n",
    "        \n",
    "        print(f\"âœ… Interaction index built: {len(self.df):,} interactions indexed\")\n",
    "    \n",
    "    def find_interaction(self, drug1, drug2):\n",
    "        \"\"\"Find interaction between two drugs\"\"\"\n",
    "        key = (drug1.lower(), drug2.lower())\n",
    "        return self.interactions.get(key, [])\n",
    "    \n",
    "    def detect_all_interactions(self, drug_list):\n",
    "        \"\"\"\n",
    "        Detect all pairwise interactions in a drug list.\n",
    "        Returns a comprehensive interaction report.\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"âš™ï¸ INTERACTION ENGINE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        interactions_found = []\n",
    "        n_drugs = len(drug_list)\n",
    "        pairs_checked = 0\n",
    "        \n",
    "        # Check all pairs\n",
    "        for i in range(n_drugs):\n",
    "            for j in range(i + 1, n_drugs):\n",
    "                drug1 = drug_list[i]\n",
    "                drug2 = drug_list[j]\n",
    "                pairs_checked += 1\n",
    "                \n",
    "                interactions = self.find_interaction(drug1, drug2)\n",
    "                \n",
    "                if interactions:\n",
    "                    for interaction in interactions:\n",
    "                        interactions_found.append({\n",
    "                            'pair': f\"{drug1} â†” {drug2}\",\n",
    "                            'drug_1': drug1,\n",
    "                            'drug_2': drug2,\n",
    "                            **interaction\n",
    "                        })\n",
    "        \n",
    "        # Sort by severity\n",
    "        severity_order = {'Contraindicated interaction': 0, 'Major interaction': 1, \n",
    "                         'Moderate interaction': 2, 'Minor interaction': 3}\n",
    "        interactions_found.sort(key=lambda x: severity_order.get(x['severity_label'], 4))\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Analysis Summary:\")\n",
    "        print(f\"   Drugs analyzed: {n_drugs}\")\n",
    "        print(f\"   Pairs checked: {pairs_checked}\")\n",
    "        print(f\"   Interactions found: {len(interactions_found)}\")\n",
    "        \n",
    "        # Severity breakdown\n",
    "        if interactions_found:\n",
    "            severity_counts = {}\n",
    "            for inter in interactions_found:\n",
    "                sev = inter['severity_label']\n",
    "                severity_counts[sev] = severity_counts.get(sev, 0) + 1\n",
    "            \n",
    "            print(f\"\\nâš ï¸ Severity Breakdown:\")\n",
    "            for sev, count in severity_counts.items():\n",
    "                emoji = \"ğŸ”´\" if \"Contraindicated\" in sev else \"ğŸŸ \" if \"Major\" in sev else \"ğŸŸ¡\" if \"Moderate\" in sev else \"ğŸŸ¢\"\n",
    "                print(f\"   {emoji} {sev}: {count}\")\n",
    "        \n",
    "        return {\n",
    "            'interactions': interactions_found,\n",
    "            'total_interactions': len(interactions_found),\n",
    "            'drugs_analyzed': n_drugs,\n",
    "            'pairs_checked': pairs_checked\n",
    "        }\n",
    "\n",
    "# Initialize Interaction Engine\n",
    "interaction_engine = InteractionEngine(df)\n",
    "\n",
    "# Test with validated drugs (excluding unrecognized)\n",
    "valid_drug_names = [d['input_name'] for d in input_result['validated_drugs']]\n",
    "interaction_result = interaction_engine.detect_all_interactions(valid_drug_names)\n",
    "\n",
    "# Display interactions\n",
    "if interaction_result['interactions']:\n",
    "    print(\"\\nğŸ“‹ Detected Interactions:\")\n",
    "    interaction_df = pd.DataFrame(interaction_result['interactions'])[\n",
    "        ['pair', 'severity_label', 'severity_confidence', 'description']\n",
    "    ]\n",
    "    interaction_df['description'] = interaction_df['description'].apply(lambda x: x[:60] + '...' if len(str(x)) > 60 else x)\n",
    "    display(interaction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ad171",
   "metadata": {},
   "source": [
    "## ğŸ§  Module 3: Severity Predictor (ML / GNN)\n",
    "\n",
    "Machine Learning and Graph Neural Network based severity prediction for drug interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
