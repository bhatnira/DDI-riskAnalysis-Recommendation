#!/usr/bin/env python3
"""
Severity Prediction Recalibration Module

Addresses the over-classification issue in zero-shot severity predictions
using a hybrid approach:

1. Confidence-based threshold recalibration
2. Clinical text marker analysis
3. Drug class risk profiling
4. Evidence-based distribution targeting

Literature baseline distribution:
- Contraindicated: ~5%
- Major: ~25%  
- Moderate: ~60%
- Minor: ~10%
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Tuple, Optional
from collections import Counter, defaultdict
from pathlib import Path
import json
import re
from dataclasses import dataclass
from scipy import stats


# ============================================================================
# CLINICAL EVIDENCE RULES
# ============================================================================

# Definitive contraindication markers (require strong evidence)
CONTRAINDICATED_MARKERS = {
    'strong': [
        'absolutely contraindicated', 'never use together', 'fatal combination',
        'lethal', 'death reported', 'potentially fatal', 'avoid combination',
        'do not administer', 'life-threatening arrhythmia'
    ],
    'moderate': [
        'torsades de pointes', 'serotonin syndrome', 'neuroleptic malignant',
        'malignant hyperthermia', 'severe hypotension', 'cardiac arrest potential'
    ]
}

# Major interaction markers
MAJOR_MARKERS = {
    'strong': [
        'serious bleeding', 'significant hemorrhage', 'severe hypotension',
        'hospitalization may be required', 'significantly increased risk',
        'substantially increased', 'marked increase', 'severe toxicity',
        'potentially life-threatening', 'requires immediate attention'
    ],
    'moderate': [
        'increased risk of bleeding', 'QT prolongation', 'increased toxicity',
        'enhanced anticoagulant effect', 'serious adverse', 'significant increase',
        'substantially reduce', 'major decrease', 'clinical significance high'
    ]
}

# Moderate interaction markers
MODERATE_MARKERS = [
    'may increase', 'may decrease', 'monitor', 'caution advised',
    'dose adjustment may be needed', 'enhanced effect', 'reduced effect',
    'consider monitoring', 'be aware', 'potential interaction',
    'clinical significance moderate', 'some increase', 'some decrease'
]

# Minor interaction markers  
MINOR_MARKERS = [
    'minor', 'minimal', 'unlikely to be clinically significant',
    'theoretical', 'small effect', 'slight increase', 'slight decrease',
    'rarely significant', 'negligible', 'clinical significance low',
    'not expected to be significant'
]

# Effect type severity markers (based on DrugBank template patterns)
# Derived from actual effect patterns in the dataset
EFFECT_TYPE_SEVERITY = {
    'contraindicated_effects': [
        # Immediately life-threatening
        'torsades de pointes', 'serotonin syndrome', 'neuroleptic malignant',
        'cardiac arrest', 'fatal', 'death', 'qt prolongation', 'qtc prolongation'
    ],
    'major_effects': [
        # Serious adverse events requiring monitoring/intervention
        'bleeding and hemorrhage', 'gastrointestinal bleeding', 'hemorrhage',
        'bleeding',  # Moved to major - bleeding risk is clinically significant
        'hyperkalemia', 'hypertensive crisis', 'severe hypotension',
        'myopathy, rhabdomyolysis', 'rhabdomyolysis', 'angioedema',
        'renal failure', 'liver damage', 'agranulocytosis',
        'thrombocytopeni', 'neutropeni', 'seizure',
        'anticoagulant activities', 'cardiotoxic', 'ototoxic', 'neurotoxic',
        'hypoglycemic activities'  # Hypoglycemia can be dangerous
    ],
    'moderate_effects': [
        # Pharmacokinetic/pharmacodynamic - require monitoring but manageable
        'hypertension', 'hypotension', 'methemoglobinemia',
        'dehydration', 'hypokalemia', 'hyponatremia', 'edema',
        'metabolism', 'serum concentration', 'therapeutic efficacy',
        'excretion rate', 'absorption', 'bioavailability',
        'protein binding', 'renal clearance', 'adverse effects can be increased',
        'myopathy', 'gastrointestinal irritation', 'extrapyramidal',
        'antihypertensive activities', 'bradycardia', 'vasodilatory activities'
    ],
    'minor_effects': [
        # Usually clinically insignificant
        'sedation', 'sedative activities', 'tendinopathy',
        'gastric', 'nausea', 'headache', 'dizziness', 
        'drowsiness', 'constipation', 'fluid retention', 'cns depressant'
    ]
}

# Drug pairs known to be contraindicated (gold standard)
KNOWN_CONTRAINDICATED_PAIRS = {
    # MAOIs + Serotonergics
    ('phenelzine', 'fluoxetine'), ('tranylcypromine', 'sertraline'),
    ('isocarboxazid', 'paroxetine'), ('selegiline', 'meperidine'),
    
    # Nitrates + PDE5 inhibitors
    ('nitroglycerin', 'sildenafil'), ('nitroglycerin', 'tadalafil'),
    ('isosorbide', 'sildenafil'), ('isosorbide', 'vardenafil'),
    
    # Potassium-sparing + Potassium
    ('spironolactone', 'potassium chloride'), ('amiloride', 'potassium'),
    ('triamterene', 'potassium supplements'),
    
    # Strong CYP3A4 inhibitors + certain statins
    ('itraconazole', 'simvastatin'), ('ketoconazole', 'lovastatin'),
    ('clarithromycin', 'simvastatin'),
    
    # QT prolonging combinations
    ('amiodarone', 'sotalol'), ('dofetilide', 'amiodarone'),
    ('haloperidol', 'thioridazine'),
}

# Drug pairs known to be major (but not contraindicated)
KNOWN_MAJOR_PAIRS = {
    # Anticoagulants + NSAIDs
    ('warfarin', 'aspirin'), ('warfarin', 'ibuprofen'), ('warfarin', 'naproxen'),
    ('rivaroxaban', 'aspirin'), ('apixaban', 'aspirin'),
    
    # Anticoagulant combinations
    ('warfarin', 'heparin'), ('warfarin', 'enoxaparin'),
    
    # Digoxin interactions
    ('digoxin', 'amiodarone'), ('digoxin', 'verapamil'), ('digoxin', 'quinidine'),
    
    # Lithium interactions
    ('lithium', 'ibuprofen'), ('lithium', 'furosemide'),
    
    # CYP interactions affecting efficacy
    ('clopidogrel', 'omeprazole'), ('clopidogrel', 'esomeprazole'),
}

# High-risk drug classes (interactions more likely to be Major+)
HIGH_RISK_DRUGS = {
    'anticoagulants': ['warfarin', 'heparin', 'enoxaparin', 'rivaroxaban', 
                       'apixaban', 'dabigatran', 'edoxaban', 'fondaparinux'],
    'antiplatelets': ['aspirin', 'clopidogrel', 'ticagrelor', 'prasugrel', 'dipyridamole'],
    'antiarrhythmics': ['amiodarone', 'sotalol', 'dofetilide', 'flecainide', 'propafenone'],
    'narrow_therapeutic': ['warfarin', 'digoxin', 'lithium', 'phenytoin', 
                          'theophylline', 'cyclosporine', 'tacrolimus', 'methotrexate'],
    'maois': ['phenelzine', 'tranylcypromine', 'isocarboxazid', 'selegiline'],
    'qt_prolonging': ['amiodarone', 'sotalol', 'dofetilide', 'haloperidol', 
                      'thioridazine', 'ziprasidone', 'droperidol', 'methadone']
}


@dataclass 
class RecalibrationConfig:
    """Configuration for severity recalibration"""
    # Target distribution (based on literature)
    target_contraindicated: float = 0.05
    target_major: float = 0.25
    target_moderate: float = 0.60
    target_minor: float = 0.10
    
    # Confidence thresholds for downgrading
    contraindicated_min_confidence: float = 0.65  # Need high confidence for contraindicated
    major_min_confidence: float = 0.45
    
    # Text marker weights (adjusted for DrugBank templated descriptions)
    marker_weight: float = 0.50  # Higher weight on effect type
    confidence_weight: float = 0.20  # Lower weight on zero-shot confidence
    drug_class_weight: float = 0.30
    
    # Enable components
    use_text_markers: bool = True
    use_drug_class_rules: bool = True
    use_known_pairs: bool = True


class SeverityRecalibrator:
    """
    Recalibrates zero-shot severity predictions using multiple evidence sources
    """
    
    SEVERITY_NUMERIC = {
        'Contraindicated interaction': 4,
        'Major interaction': 3,
        'Moderate interaction': 2,
        'Minor interaction': 1
    }
    
    NUMERIC_TO_SEVERITY = {
        4: 'Contraindicated interaction',
        3: 'Major interaction', 
        2: 'Moderate interaction',
        1: 'Minor interaction'
    }
    
    def __init__(self, config: RecalibrationConfig = None):
        self.config = config or RecalibrationConfig()
        self.recalibration_stats = {}
        
    def _normalize_drug_name(self, name: str) -> str:
        """Normalize drug name for matching"""
        return name.lower().strip()
    
    def _check_known_pair(self, drug1: str, drug2: str) -> Optional[str]:
        """Check if drug pair is in known severity lists"""
        d1 = self._normalize_drug_name(drug1)
        d2 = self._normalize_drug_name(drug2)
        
        # Check contraindicated pairs
        for p1, p2 in KNOWN_CONTRAINDICATED_PAIRS:
            if (p1 in d1 and p2 in d2) or (p1 in d2 and p2 in d1):
                return 'Contraindicated interaction'
        
        # Check major pairs
        for p1, p2 in KNOWN_MAJOR_PAIRS:
            if (p1 in d1 and p2 in d2) or (p1 in d2 and p2 in d1):
                return 'Major interaction'
        
        return None
    
    def _get_drug_risk_class(self, drug1: str, drug2: str) -> str:
        """Determine risk class based on drug classes"""
        d1 = self._normalize_drug_name(drug1)
        d2 = self._normalize_drug_name(drug2)
        
        d1_classes = set()
        d2_classes = set()
        
        for cls, drugs in HIGH_RISK_DRUGS.items():
            if any(d in d1 for d in drugs):
                d1_classes.add(cls)
            if any(d in d2 for d in drugs):
                d2_classes.add(cls)
        
        # Both drugs in same high-risk class = higher severity
        overlap = d1_classes & d2_classes
        
        if 'maois' in overlap:
            return 'very_high'
        if 'anticoagulants' in overlap or 'qt_prolonging' in overlap:
            return 'high'
        if d1_classes and d2_classes:  # Both have some risk class
            return 'elevated'
        if d1_classes or d2_classes:  # One has risk class
            return 'moderate'
        
        return 'standard'
    
    def _analyze_text_markers(self, description: str) -> Dict[str, float]:
        """Analyze interaction description for severity markers"""
        if pd.isna(description):
            return {'score': 2.0, 'evidence': 'none'}
        
        desc_lower = description.lower()
        
        # Check for effect type severity (DrugBank template patterns)
        # Order matters: check more specific/severe patterns first
        
        # 1. Contraindicated effects (immediately life-threatening)
        for effect in EFFECT_TYPE_SEVERITY['contraindicated_effects']:
            if effect in desc_lower:
                return {'score': 4.0, 'evidence': 'contra_effect', 'marker': effect}
        
        # 2. Major effects (serious adverse events)
        # Check these before moderate since some are substrings
        for effect in sorted(EFFECT_TYPE_SEVERITY['major_effects'], key=len, reverse=True):
            if effect in desc_lower:
                return {'score': 3.2, 'evidence': 'major_effect', 'marker': effect}
        
        # 3. Check legacy contraindicated markers (clinical phrasing)
        contra_strong = sum(1 for m in CONTRAINDICATED_MARKERS['strong'] if m in desc_lower)
        if contra_strong >= 1:
            return {'score': 4.0, 'evidence': 'strong_contra', 'markers': contra_strong}
        
        # 4. Check legacy major markers
        major_strong = sum(1 for m in MAJOR_MARKERS['strong'] if m in desc_lower)
        if major_strong >= 1:
            return {'score': 3.0, 'evidence': 'strong_major', 'markers': major_strong}
        
        # 5. Moderate effects (pharmacokinetic, manageable effects)
        for effect in sorted(EFFECT_TYPE_SEVERITY['moderate_effects'], key=len, reverse=True):
            if effect in desc_lower:
                return {'score': 2.0, 'evidence': 'moderate_effect', 'marker': effect}
        
        # 6. Minor effects
        for effect in EFFECT_TYPE_SEVERITY['minor_effects']:
            if effect in desc_lower:
                return {'score': 1.5, 'evidence': 'minor_effect', 'marker': effect}
        
        # Default: No specific clinical marker found
        # These typically describe generic PK effects without clinical severity
        return {'score': 1.6, 'evidence': 'default'}
    
    def _compute_recalibrated_severity(self, row: pd.Series) -> Dict[str, Any]:
        """
        Compute recalibrated severity for a single interaction
        
        Combines:
        1. Original prediction confidence
        2. Text marker analysis
        3. Drug class risk profiling
        4. Known pair lookup
        """
        drug1 = row['drug_name_1']
        drug2 = row['drug_name_2']
        original_severity = row['severity_label']
        original_confidence = row['severity_confidence']
        description = row['interaction_description']
        
        # Check known pairs first (highest priority)
        if self.config.use_known_pairs:
            known = self._check_known_pair(drug1, drug2)
            if known:
                return {
                    'severity': known,
                    'method': 'known_pair',
                    'confidence': 0.95,
                    'original': original_severity
                }
        
        # Calculate component scores
        scores = {}
        
        # 1. Original zero-shot score (adjusted by confidence)
        original_numeric = self.SEVERITY_NUMERIC.get(original_severity, 2)
        # Penalize low confidence predictions toward moderate
        confidence_adjusted = original_numeric
        if original_confidence < self.config.contraindicated_min_confidence and original_numeric == 4:
            confidence_adjusted = 3.0  # Downgrade to major
        elif original_confidence < self.config.major_min_confidence and original_numeric >= 3:
            confidence_adjusted = 2.5  # Partial downgrade toward moderate
        scores['zeroshot'] = confidence_adjusted
        
        # 2. Text marker score
        if self.config.use_text_markers:
            marker_result = self._analyze_text_markers(description)
            scores['markers'] = marker_result['score']
        else:
            scores['markers'] = 2.0
        
        # 3. Drug class risk score
        if self.config.use_drug_class_rules:
            risk_class = self._get_drug_risk_class(drug1, drug2)
            risk_scores = {
                'very_high': 4.0,
                'high': 3.5,
                'elevated': 3.0,
                'moderate': 2.5,
                'standard': 2.0
            }
            scores['drug_class'] = risk_scores.get(risk_class, 2.0)
        else:
            scores['drug_class'] = 2.0
        
        # Weighted combination
        final_score = (
            self.config.confidence_weight * scores['zeroshot'] +
            self.config.marker_weight * scores['markers'] +
            self.config.drug_class_weight * scores['drug_class']
        )
        
        # Convert to severity label with thresholds
        # Thresholds tuned through iterative calibration:
        # 
        # Current marker distribution from data analysis:
        # - ~4% trigger contraindicated effects (QTc, serotonin syndrome)
        # - ~14% trigger major effects (bleeding, hyperkalemia)
        # - ~65% trigger moderate effects (PK changes)
        # - ~17% have no specific marker (default)
        # 
        # Target: 5% contra, 25% major, 60% moderate, 10% minor
        if final_score >= 3.2:  # ~3-5% (only strongest evidence)
            new_severity = 'Contraindicated interaction'
        elif final_score >= 2.50:  # ~20-25% 
            new_severity = 'Major interaction'
        elif final_score >= 2.00:  # ~60%
            new_severity = 'Moderate interaction'
        else:  # ~10-15%
            new_severity = 'Minor interaction'
        
        return {
            'severity': new_severity,
            'method': 'hybrid',
            'confidence': min(0.95, original_confidence + 0.1),  # Slight boost for hybrid
            'original': original_severity,
            'scores': scores,
            'final_score': final_score
        }
    
    def recalibrate_dataset(self, df: pd.DataFrame, 
                           show_progress: bool = True) -> pd.DataFrame:
        """
        Recalibrate severity predictions for entire dataset
        
        Args:
            df: DataFrame with severity_label, severity_confidence, interaction_description
            show_progress: Print progress updates
            
        Returns:
            DataFrame with new columns: severity_recalibrated, recal_confidence, recal_method
        """
        print("\n" + "="*70)
        print("SEVERITY RECALIBRATION")
        print("="*70)
        print(f"Processing {len(df):,} interactions...")
        print(f"\nConfiguration:")
        print(f"   Marker weight: {self.config.marker_weight}")
        print(f"   Confidence weight: {self.config.confidence_weight}")
        print(f"   Drug class weight: {self.config.drug_class_weight}")
        print(f"   Min confidence for Contraindicated: {self.config.contraindicated_min_confidence}")
        
        # Initialize new columns
        recalibrated = []
        methods = []
        confidences = []
        
        # Process each row
        for i, (_, row) in enumerate(df.iterrows()):
            if show_progress and (i + 1) % 100000 == 0:
                print(f"   Progress: {i+1:,}/{len(df):,} ({(i+1)/len(df)*100:.1f}%)")
            
            result = self._compute_recalibrated_severity(row)
            recalibrated.append(result['severity'])
            methods.append(result['method'])
            confidences.append(result['confidence'])
        
        # Add to dataframe
        df_recal = df.copy()
        df_recal['severity_recalibrated'] = recalibrated
        df_recal['recal_confidence'] = confidences
        df_recal['recal_method'] = methods
        
        # Calculate statistics
        self._compute_stats(df, df_recal)
        
        return df_recal
    
    def _compute_stats(self, df_original: pd.DataFrame, df_recal: pd.DataFrame):
        """Compute recalibration statistics"""
        print("\n" + "-"*50)
        print("RECALIBRATION RESULTS")
        print("-"*50)
        
        # Distribution comparison
        orig_dist = df_original['severity_label'].value_counts(normalize=True)
        recal_dist = df_recal['severity_recalibrated'].value_counts(normalize=True)
        
        target_dist = {
            'Contraindicated interaction': self.config.target_contraindicated,
            'Major interaction': self.config.target_major,
            'Moderate interaction': self.config.target_moderate,
            'Minor interaction': self.config.target_minor
        }
        
        print("\n   Distribution Comparison:")
        print(f"   {'Severity':<30} {'Original':>10} {'Recalibrated':>12} {'Target':>10}")
        print("   " + "-"*65)
        
        for sev in ['Contraindicated interaction', 'Major interaction', 
                    'Moderate interaction', 'Minor interaction']:
            orig = orig_dist.get(sev, 0)
            recal = recal_dist.get(sev, 0)
            target = target_dist[sev]
            print(f"   {sev:<30} {orig:>9.1%} {recal:>11.1%} {target:>9.1%}")
        
        # Changes made
        changes = (df_original['severity_label'] != df_recal['severity_recalibrated']).sum()
        print(f"\n   Total changes: {changes:,} ({changes/len(df_original)*100:.1f}%)")
        
        # Change matrix
        print("\n   Change Matrix (Original â†’ Recalibrated):")
        change_matrix = pd.crosstab(
            df_original['severity_label'], 
            df_recal['severity_recalibrated'],
            margins=True
        )
        
        # Store stats
        self.recalibration_stats = {
            'original_distribution': orig_dist.to_dict(),
            'recalibrated_distribution': recal_dist.to_dict(),
            'target_distribution': target_dist,
            'total_changes': int(changes),
            'change_rate': float(changes / len(df_original)),
            'change_matrix': change_matrix.to_dict()
        }
        
        # Method breakdown
        method_counts = df_recal['recal_method'].value_counts()
        print("\n   Recalibration Methods Used:")
        for method, count in method_counts.items():
            print(f"      {method}: {count:,} ({count/len(df_recal)*100:.1f}%)")
    
    def validate_recalibration(self, df_recal: pd.DataFrame) -> Dict[str, Any]:
        """Validate recalibrated predictions against clinical expectations"""
        print("\n" + "="*70)
        print("RECALIBRATION VALIDATION")
        print("="*70)
        
        results = {}
        
        # 1. Check high-risk combinations
        anticoag = ['warfarin', 'heparin', 'rivaroxaban', 'apixaban', 'dabigatran']
        antiplatelet = ['aspirin', 'clopidogrel', 'ticagrelor']
        
        mask = (
            (df_recal['drug_name_1'].str.lower().isin(anticoag) & 
             df_recal['drug_name_2'].str.lower().isin(antiplatelet)) |
            (df_recal['drug_name_1'].str.lower().isin(antiplatelet) & 
             df_recal['drug_name_2'].str.lower().isin(anticoag))
        )
        
        if mask.any():
            high_risk = df_recal[mask]
            major_plus = high_risk['severity_recalibrated'].isin(
                ['Contraindicated interaction', 'Major interaction']
            ).mean()
            results['anticoag_antiplatelet'] = float(major_plus)
            print(f"\n   âœ“ Anticoagulant+Antiplatelet Major+ rate: {major_plus:.1%}")
        
        # 2. Check expected moderate interactions
        moderate_count = (df_recal['severity_recalibrated'] == 'Moderate interaction').sum()
        moderate_rate = moderate_count / len(df_recal)
        results['moderate_rate'] = float(moderate_rate)
        
        status = "âœ“" if 0.3 <= moderate_rate <= 0.7 else "âš ï¸"
        print(f"   {status} Moderate interaction rate: {moderate_rate:.1%} (target: 60%)")
        
        # 3. Check contraindicated rate
        contra_rate = (df_recal['severity_recalibrated'] == 'Contraindicated interaction').mean()
        results['contraindicated_rate'] = float(contra_rate)
        
        status = "âœ“" if contra_rate <= 0.15 else "âš ï¸"
        print(f"   {status} Contraindicated rate: {contra_rate:.1%} (target: 5%)")
        
        # 4. Confidence improvement
        mean_conf_orig = df_recal['severity_confidence'].mean()
        mean_conf_recal = df_recal['recal_confidence'].mean()
        results['confidence_improvement'] = float(mean_conf_recal - mean_conf_orig)
        print(f"   âœ“ Mean confidence: {mean_conf_orig:.3f} â†’ {mean_conf_recal:.3f}")
        
        return results


def run_recalibration():
    """Main recalibration runner"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Recalibrate severity predictions')
    parser.add_argument('--data', type=str, 
                       default='data/ddi_cardio_or_antithrombotic_labeled (1).csv',
                       help='Path to DDI data')
    parser.add_argument('--output', type=str, 
                       default='data/ddi_recalibrated.csv',
                       help='Output path for recalibrated data')
    parser.add_argument('--marker-weight', type=float, default=0.4,
                       help='Weight for text marker analysis')
    parser.add_argument('--confidence-weight', type=float, default=0.3,
                       help='Weight for original confidence')
    parser.add_argument('--drug-class-weight', type=float, default=0.3,
                       help='Weight for drug class rules')
    args = parser.parse_args()
    
    print("Loading data...")
    df = pd.read_csv(args.data)
    print(f"Loaded {len(df):,} interactions")
    
    # Show original distribution
    print("\nOriginal Distribution:")
    print(df['severity_label'].value_counts())
    
    # Configure and run recalibration
    config = RecalibrationConfig(
        marker_weight=args.marker_weight,
        confidence_weight=args.confidence_weight,
        drug_class_weight=args.drug_class_weight
    )
    
    recalibrator = SeverityRecalibrator(config)
    df_recal = recalibrator.recalibrate_dataset(df)
    
    # Validate
    validation = recalibrator.validate_recalibration(df_recal)
    
    # Save
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    df_recal.to_csv(output_path, index=False)
    print(f"\nðŸ“„ Recalibrated data saved to: {output_path}")
    
    # Save stats
    stats_path = output_path.with_suffix('.json')
    with open(stats_path, 'w') as f:
        json.dump({
            'config': {
                'marker_weight': config.marker_weight,
                'confidence_weight': config.confidence_weight,
                'drug_class_weight': config.drug_class_weight
            },
            'stats': recalibrator.recalibration_stats,
            'validation': validation
        }, f, indent=2, default=str)
    print(f"ðŸ“Š Statistics saved to: {stats_path}")
    
    return df_recal


if __name__ == "__main__":
    run_recalibration()
